{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fastora\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Fastora\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\Fastora\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipe_model import CBOW\n",
    "from recipe_dataset import RecipeText2DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 27534\n",
    "EMBEDDING_DIM = 50\n",
    "WINDOW_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (embedding): Embedding(27534, 50)\n",
       "  (linear): Linear(in_features=50, out_features=27534, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CBOW(VOCAB_SIZE, EMBEDDING_DIM, WINDOW_SIZE)\n",
    "model.load_state_dict(torch.load('Models/model_249', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 27534\n"
     ]
    }
   ],
   "source": [
    "data = RecipeText2DataSet('data/ar_recipes_corpus.txt', window_size=WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_json('data/recipes_cleaned_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = model.embedding.weight.data.numpy()\n",
    "word2idx = data.word2idx\n",
    "idx2word = data.idx2word\n",
    "pkl.dump(word2idx, open('data/word2idx.pkl', 'wb'))\n",
    "pkl.dump(idx2word, open('data/idx2word.pkl', 'wb'))\n",
    "pkl.dump(embedding_matrix, open('data/embedding_matrix.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_k_nearest(X, idx, k, idx_to_word):\n",
    "    dists = np.dot((X - X[idx])**2, np.ones(X.shape[1]))\n",
    "    ids = np.argsort(dists)[:k]\n",
    "    scores = [dists[i] for i in ids]\n",
    "    print('Nearest to {}:'.format(idx_to_word[idx]))\n",
    "    for i in ids:\n",
    "        print(idx_to_word[i])\n",
    "    print('\\n')\n",
    "    return ids, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest(X, idx, k, idx_to_word):\n",
    "    dists = np.dot((X - X[idx])**2, np.ones(X.shape[1]))\n",
    "    ids = np.argsort(dists)[:k]\n",
    "    scores = [dists[i] for i in ids]\n",
    "    return ids, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in recipes.iterrows():\n",
    "    ing = []\n",
    "    for j in data['ingredients']:\n",
    "        ing.append(j['ingredient'])\n",
    "    data['ingredients'] = ing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique ingredients\n",
    "unique_ingredients = set()\n",
    "for i, data in recipes.iterrows():\n",
    "    for j in data['ingredients']:\n",
    "        unique_ingredients.add(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe_vector(recipe_id, word2idx):\n",
    "    recipe = recipes.iloc[recipe_id]\n",
    "    recipe_ings = recipe['ingredients']\n",
    "    recipe_steps = recipe['steps']\n",
    "    recipe_tags = recipe['tags']\n",
    "    recipe_name = str(recipe['name'])\n",
    "    recipe_cuisine = str(recipe['cuisine'])\n",
    "\n",
    "    #tokenize each list \n",
    "    recipe_ings = [word_tokenize(ing) for ing in recipe_ings]\n",
    "    recipe_steps = [word_tokenize(step) for step in recipe_steps]\n",
    "    recipe_tags = [word_tokenize(tag) for tag in recipe_tags]\n",
    "    recipe_name = word_tokenize(recipe_name)\n",
    "    recipe_cuisine = word_tokenize(recipe_cuisine)\n",
    "\n",
    "    #flatten each list\n",
    "    recipe_ings = [item for sublist in recipe_ings for item in sublist]\n",
    "    recipe_steps = [item for sublist in recipe_steps for item in sublist]\n",
    "    recipe_tags = [item for sublist in recipe_tags for item in sublist]\n",
    "\n",
    "    #get embeddings for each word in each list\n",
    "    recipe_ings = [embedding_matrix[word2idx[ing]] for ing in recipe_ings if ing in word2idx]\n",
    "    recipe_steps = [embedding_matrix[word2idx[step]] for step in recipe_steps if step in word2idx]\n",
    "    recipe_tags = [embedding_matrix[word2idx[tag]] for tag in recipe_tags if tag in word2idx]\n",
    "    recipe_name = [embedding_matrix[word2idx[name]] for name in recipe_name if name in word2idx]\n",
    "    recipe_cuisine = [embedding_matrix[word2idx[cuisine]] for cuisine in recipe_cuisine if cuisine in word2idx]\n",
    "\n",
    "    #average the embeddings for each list if the list has more than 1 word\n",
    "    recipe_ings = np.mean(recipe_ings, axis=0)\n",
    "    recipe_steps = np.mean(recipe_steps, axis=0)\n",
    "    recipe_tags = np.mean(recipe_tags, axis=0)\n",
    "    recipe_name = np.mean(recipe_name, axis=0)\n",
    "    recipe_cuisine = np.mean(recipe_cuisine, axis=0)\n",
    "\n",
    "    #if the list has only 1 word, skip this r\n",
    "    if type(recipe_ings) == np.float64:\n",
    "        recipe_ings = np.zeros(EMBEDDING_DIM)\n",
    "    if type(recipe_steps) == np.float64:\n",
    "        recipe_steps = np.zeros(EMBEDDING_DIM)\n",
    "    if type(recipe_tags) == np.float64:\n",
    "        recipe_tags = np.zeros(EMBEDDING_DIM)\n",
    "    if type(recipe_name) == np.float64:\n",
    "        recipe_name = np.zeros(EMBEDDING_DIM)\n",
    "    if type(recipe_cuisine) == np.float64:\n",
    "        recipe_cuisine = np.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    #check if any of the lists are empty\n",
    "    if len(recipe_ings) == 0:\n",
    "        recipe_ings = np.zeros(EMBEDDING_DIM)\n",
    "    if len(recipe_steps) == 0:\n",
    "        recipe_steps = np.zeros(EMBEDDING_DIM)\n",
    "    if len(recipe_tags) == 0:\n",
    "        recipe_tags = np.zeros(EMBEDDING_DIM)\n",
    "    if len(recipe_name) == 0:\n",
    "        recipe_name = np.zeros(EMBEDDING_DIM)\n",
    "    if len(recipe_cuisine) == 0:\n",
    "        recipe_cuisine = np.zeros(EMBEDDING_DIM)\n",
    "    #concatenate the embeddings for each list\n",
    "    recipe_vector = np.concatenate((recipe_ings, recipe_steps, recipe_tags, recipe_name, recipe_cuisine), axis=0)\n",
    "    return recipe_vector, recipe_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15911 [00:00<?, ?it/s]c:\\Users\\Fastora\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Fastora\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 37%|███▋      | 5835/15911 [00:10<00:19, 522.00it/s]"
     ]
    }
   ],
   "source": [
    "recipes_matrix = []\n",
    "for i, data in tqdm(recipes.iterrows(), total=recipes.shape[0]):\n",
    "    r = get_recipe_vector(i, word2idx)\n",
    "    recipes_matrix.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(recipes_matrix, open('data/recipes_matrix.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest_recipes(recipe_id, k, recipes_matrix):\n",
    "    #recipes matrix is a list of vectors (recipe_vector, recipe_id)\n",
    "    recipe_vector = recipes_matrix[recipe_id][0]\n",
    "    #extract ingredients vector from each recipe vector\n",
    "    recipes_m = [r[0] for r in recipes_matrix]\n",
    "    recipes_m = np.array(recipes_m)\n",
    "    dists = np.dot((recipes_m - recipe_vector)**2, np.ones(recipes_m.shape[1]))\n",
    "    ids = np.argsort(dists)[:k]\n",
    "    r_id = recipes_matrix[recipe_id][1]\n",
    "    re_name = recipes.iloc[r_id]['name']\n",
    "    print('Nearest to {}:'.format(re_name))\n",
    "    for i in ids:\n",
    "        r_id = recipes_matrix[i][1]\n",
    "        re_name = recipes.iloc[r_id]['name']\n",
    "        print(re_name)\n",
    "    print('\\n')\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15911, 250)\n",
      "(250,)\n",
      "Nearest to مهلبية البطاطا الحلوة:\n",
      "مهلبية البطاطا الحلوة\n",
      "فيديو كيكة جوز الهند الهشة\n",
      "سلطة البطاطا الحلوة\n",
      "كرات جوز الهند بالشوكولاتة البيضاء واللوز\n",
      "مهلبية الشوكولاتة بجوز الهند\n",
      "مهلبية الشوفان بجوز الهند\n",
      "سلطة البطاطا الحلوة\n",
      "شوربة الخضار مع الأرز\n",
      "مهلبية الشوفان\n",
      "مهلبية جوز الهند الشهية\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fastora\\AppData\\Local\\Temp\\ipykernel_19304\\2672925712.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  get_k_nearest_recipes(51, 10, np.array(recipes_matrix))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   51,  4845,  8389,   467, 11682,  9642,  5716,  5240,  6332,\n",
       "        4325], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_k_nearest_recipes(51, 10, np.array(recipes_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
